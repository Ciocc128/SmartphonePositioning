{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/Volumes/Mac/DatasetSP/pipeline2/combined_features_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Test</th>\n",
       "      <th>Trial</th>\n",
       "      <th>Bout</th>\n",
       "      <th>Position</th>\n",
       "      <th>Acc_X_Var</th>\n",
       "      <th>Acc_X_RMS</th>\n",
       "      <th>Acc_X_SMA</th>\n",
       "      <th>Acc_X_NumPeaks</th>\n",
       "      <th>Acc_X_DomFreq</th>\n",
       "      <th>...</th>\n",
       "      <th>Gyr_Z_DomFreq</th>\n",
       "      <th>Gyr_Z_DomPower</th>\n",
       "      <th>Gyr_Z_SpecEntropy</th>\n",
       "      <th>Gyr_Norm_Var</th>\n",
       "      <th>Gyr_Norm_RMS</th>\n",
       "      <th>Gyr_Norm_SMA</th>\n",
       "      <th>Gyr_Norm_NumPeaks</th>\n",
       "      <th>Gyr_Norm_DomFreq</th>\n",
       "      <th>Gyr_Norm_DomPower</th>\n",
       "      <th>Gyr_Norm_SpecEntropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "      <td>105209.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.955080</td>\n",
       "      <td>9.549117</td>\n",
       "      <td>3.552614</td>\n",
       "      <td>13.932734</td>\n",
       "      <td>2.452138</td>\n",
       "      <td>8.270679</td>\n",
       "      <td>7.995806</td>\n",
       "      <td>7.524544</td>\n",
       "      <td>21.557566</td>\n",
       "      <td>1.984675</td>\n",
       "      <td>...</td>\n",
       "      <td>1.539989</td>\n",
       "      <td>5194.642667</td>\n",
       "      <td>4.338527</td>\n",
       "      <td>2964.968677</td>\n",
       "      <td>97.222385</td>\n",
       "      <td>85.304637</td>\n",
       "      <td>24.618882</td>\n",
       "      <td>1.649868</td>\n",
       "      <td>5129.851613</td>\n",
       "      <td>4.618699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.536324</td>\n",
       "      <td>1.196259</td>\n",
       "      <td>1.048692</td>\n",
       "      <td>11.981405</td>\n",
       "      <td>1.704596</td>\n",
       "      <td>9.782387</td>\n",
       "      <td>3.003762</td>\n",
       "      <td>2.954363</td>\n",
       "      <td>4.303126</td>\n",
       "      <td>1.189416</td>\n",
       "      <td>...</td>\n",
       "      <td>1.050549</td>\n",
       "      <td>5322.966559</td>\n",
       "      <td>0.294788</td>\n",
       "      <td>4421.555073</td>\n",
       "      <td>56.990357</td>\n",
       "      <td>49.580597</td>\n",
       "      <td>7.094725</td>\n",
       "      <td>1.187916</td>\n",
       "      <td>3756.954804</td>\n",
       "      <td>0.270135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.070292</td>\n",
       "      <td>0.069966</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.589329</td>\n",
       "      <td>2.482545</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.072882</td>\n",
       "      <td>0.066181</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.365878</td>\n",
       "      <td>2.934905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.431045</td>\n",
       "      <td>5.435751</td>\n",
       "      <td>4.951134</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2335.889622</td>\n",
       "      <td>4.179326</td>\n",
       "      <td>586.763612</td>\n",
       "      <td>52.791321</td>\n",
       "      <td>46.400970</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2514.730552</td>\n",
       "      <td>4.474205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.276473</td>\n",
       "      <td>9.544130</td>\n",
       "      <td>9.185090</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3635.712427</td>\n",
       "      <td>4.364282</td>\n",
       "      <td>1547.179659</td>\n",
       "      <td>84.457471</td>\n",
       "      <td>74.372315</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4155.232317</td>\n",
       "      <td>4.664772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.593992</td>\n",
       "      <td>10.063291</td>\n",
       "      <td>9.705929</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5840.479340</td>\n",
       "      <td>4.536658</td>\n",
       "      <td>3652.364281</td>\n",
       "      <td>130.769748</td>\n",
       "      <td>115.204345</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6565.516793</td>\n",
       "      <td>4.810157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>516.422327</td>\n",
       "      <td>26.711397</td>\n",
       "      <td>17.730761</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>56304.119592</td>\n",
       "      <td>5.673936</td>\n",
       "      <td>130617.824302</td>\n",
       "      <td>587.701373</td>\n",
       "      <td>508.672772</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>56790.240330</td>\n",
       "      <td>5.670880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Subject           Test          Trial           Bout  \\\n",
       "count  105209.000000  105209.000000  105209.000000  105209.000000   \n",
       "mean       10.955080       9.549117       3.552614      13.932734   \n",
       "std         7.536324       1.196259       1.048692      11.981405   \n",
       "min         1.000000       4.000000       1.000000       1.000000   \n",
       "25%         3.000000      10.000000       4.000000       3.000000   \n",
       "50%         9.000000      10.000000       4.000000      10.000000   \n",
       "75%        17.000000      10.000000       4.000000      24.000000   \n",
       "max        25.000000      10.000000       4.000000      72.000000   \n",
       "\n",
       "            Position      Acc_X_Var      Acc_X_RMS      Acc_X_SMA  \\\n",
       "count  105209.000000  105209.000000  105209.000000  105209.000000   \n",
       "mean        2.452138       8.270679       7.995806       7.524544   \n",
       "std         1.704596       9.782387       3.003762       2.954363   \n",
       "min         0.000000       0.000023       0.070292       0.069966   \n",
       "25%         1.000000       2.431045       5.435751       4.951134   \n",
       "50%         2.000000       5.276473       9.544130       9.185090   \n",
       "75%         4.000000      10.593992      10.063291       9.705929   \n",
       "max         5.000000     516.422327      26.711397      17.730761   \n",
       "\n",
       "       Acc_X_NumPeaks  Acc_X_DomFreq  ...  Gyr_Z_DomFreq  Gyr_Z_DomPower  \\\n",
       "count   105209.000000  105209.000000  ...  105209.000000   105209.000000   \n",
       "mean        21.557566       1.984675  ...       1.539989     5194.642667   \n",
       "std          4.303126       1.189416  ...       1.050549     5322.966559   \n",
       "min          5.000000       0.333333  ...       0.333333        1.589329   \n",
       "25%         19.000000       1.666667  ...       1.000000     2335.889622   \n",
       "50%         22.000000       1.666667  ...       1.000000     3635.712427   \n",
       "75%         25.000000       2.000000  ...       2.000000     5840.479340   \n",
       "max         54.000000      20.000000  ...      15.666667    56304.119592   \n",
       "\n",
       "       Gyr_Z_SpecEntropy   Gyr_Norm_Var   Gyr_Norm_RMS   Gyr_Norm_SMA  \\\n",
       "count      105209.000000  105209.000000  105209.000000  105209.000000   \n",
       "mean            4.338527    2964.968677      97.222385      85.304637   \n",
       "std             0.294788    4421.555073      56.990357      49.580597   \n",
       "min             2.482545       0.000776       0.072882       0.066181   \n",
       "25%             4.179326     586.763612      52.791321      46.400970   \n",
       "50%             4.364282    1547.179659      84.457471      74.372315   \n",
       "75%             4.536658    3652.364281     130.769748     115.204345   \n",
       "max             5.673936  130617.824302     587.701373     508.672772   \n",
       "\n",
       "       Gyr_Norm_NumPeaks  Gyr_Norm_DomFreq  Gyr_Norm_DomPower  \\\n",
       "count      105209.000000     105209.000000      105209.000000   \n",
       "mean           24.618882          1.649868        5129.851613   \n",
       "std             7.094725          1.187916        3756.954804   \n",
       "min             3.000000          0.333333           1.365878   \n",
       "25%            19.000000          0.666667        2514.730552   \n",
       "50%            25.000000          1.666667        4155.232317   \n",
       "75%            30.000000          2.000000        6565.516793   \n",
       "max            77.000000         14.000000       56790.240330   \n",
       "\n",
       "       Gyr_Norm_SpecEntropy  \n",
       "count         105209.000000  \n",
       "mean               4.618699  \n",
       "std                0.270135  \n",
       "min                2.934905  \n",
       "25%                4.474205  \n",
       "50%                4.664772  \n",
       "75%                4.810157  \n",
       "max                5.670880  \n",
       "\n",
       "[8 rows x 61 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "costruction_set = data[data['Subject'].isin([8, 16, 1, 9, 6, 19, 20, 17, 4, 7, 25, 3])]\n",
    "test_set = data[data['Subject'].isin([2, 15, 22])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "costruction_set.to_csv('/Volumes/Mac/DatasetSP/pipeline2/construction_set_2.csv', index=False)\n",
    "test_set.to_csv('/Volumes/Mac/DatasetSP/pipeline2/test_set_2.2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperimento MLflow inizializzato!\n",
      "Caricamento del dataset...\n",
      "Dataset caricato con successo!\n",
      "Preprocessing dei dati...\n",
      "Preprocessing completato!\n"
     ]
    }
   ],
   "source": [
    "# Installazione di MLflow se necessario\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")  # Imposta il percorso per salvare i log\n",
    "mlflow.set_experiment(\"Pipeline2.2\")  # Nome dell'esperimento\n",
    "\n",
    "print(\"Esperimento MLflow inizializzato!\")\n",
    "\n",
    "# Funzione per caricare il dataset\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# Funzione per preprocessare i dati\n",
    "def preprocess_data(data):\n",
    "    X = data.drop(columns=['Position', 'Subject', 'Trial', 'Test', 'Bout'])\n",
    "    y = data['Position']\n",
    "    subjects = data['Subject']\n",
    "    return X, y, subjects\n",
    "\n",
    "# Percorso del dataset\n",
    "data_file = \"/Volumes/Mac/DatasetSP/pipeline2/construction_set_2.2.csv\"\n",
    "\n",
    "# Caricamento dati\n",
    "print(\"Caricamento del dataset...\")\n",
    "data = load_data(data_file)\n",
    "print(\"Dataset caricato con successo!\")\n",
    "\n",
    "print(\"Preprocessing dei dati...\")\n",
    "X, y, subjects = preprocess_data(data)\n",
    "print(\"Preprocessing completato!\")\n",
    "\n",
    "# Definizione input per i modelli\n",
    "input_dim = X.shape[1]\n",
    "num_classes = len(np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errore: Il file /Users/giorgio/Desktop/SmartphonePositioning/src/modeling/fold_indices_p2.2.pkl non esiste.\n",
      "Folds salvati in /Users/giorgio/Desktop/SmartphonePositioning/src/modeling/fold_indices_p2.2.pkl\n",
      "Folds caricati da /Users/giorgio/Desktop/SmartphonePositioning/src/modeling/fold_indices_p2.2.pkl\n"
     ]
    }
   ],
   "source": [
    "# Funzione per generare e salvare i fold\n",
    "def save_folds(X, y, subjects, n_splits=5, save_path=\"fold_indices.pkl\"):\n",
    "    group_kfold = GroupKFold(n_splits=n_splits)\n",
    "    folds = list(group_kfold.split(X, y, groups=subjects))\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(folds, f)\n",
    "    print(f\"Folds salvati in {save_path}\")\n",
    "\n",
    "# Funzione per caricare i fold\n",
    "def load_folds(load_path=\"fold_indices.pkl\"):\n",
    "    try:\n",
    "        with open(load_path, \"rb\") as f:\n",
    "            folds = pickle.load(f)\n",
    "        print(f\"Folds caricati da {load_path}\")\n",
    "        return folds\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Errore: Il file {load_path} non esiste.\")\n",
    "        return None\n",
    "\n",
    "# Creazione o caricamento dei fold\n",
    "fold_path = \"/Users/giorgio/Desktop/SmartphonePositioning/src/modeling/fold_indices_p2.2.pkl\"\n",
    "folds = load_folds(fold_path)\n",
    "if folds is None:\n",
    "    save_folds(X, y, subjects, save_path=fold_path)\n",
    "    folds = load_folds(fold_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name, fold_idx):\n",
    "    \"\"\"Genera e salva la Confusion Matrix come immagine.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_true), yticklabels=np.unique(y_true))\n",
    "    plt.xlabel(\"Predetto\")\n",
    "    plt.ylabel(\"Reale\")\n",
    "    plt.title(f\"Confusion Matrix - {model_name} (Fold {fold_idx})\")\n",
    "\n",
    "    # Salvataggio immagine\n",
    "    cm_filename = f\"{model_name}_confusion_matrix_fold_{fold_idx}.png\"\n",
    "    plt.savefig(cm_filename)\n",
    "    plt.close()\n",
    "\n",
    "    return cm_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_jobs=8, max_depth=8, colsample_bytree=0.8, subsample=0.8, n_estimators=150, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(n_jobs=-1, max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "def train_and_evaluate_mlflow(model_name, model, X, y, subjects, folds, experiment_name):\n",
    "    print(f\"\\nInizio training modello: {model_name}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Inizializza l'esperimento in MLflow\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Definizione dei percorsi per l'organizzazione dei file\n",
    "        experiment_path = os.path.join(\"mlruns\", experiment_name)\n",
    "        model_path = os.path.join(experiment_path, \"models\", model_name)\n",
    "        log_path = os.path.join(experiment_path, \"logs\", model_name)\n",
    "        artifact_path = os.path.join(experiment_path, \"artifacts\", model_name)\n",
    "\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        os.makedirs(log_path, exist_ok=True)\n",
    "        os.makedirs(artifact_path, exist_ok=True)\n",
    "\n",
    "        # Log dei parametri del modello\n",
    "        if hasattr(model, \"get_params\"):\n",
    "            params = model.get_params()\n",
    "            mlflow.log_params(params)  # Logga tutti i parametri del modello\n",
    "        else:\n",
    "            print(f\"[{model_name}] Nessun parametro disponibile per il log.\")\n",
    "\n",
    "        cv_scores = []\n",
    "        reports = []\n",
    "\n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(tqdm(folds, desc=\"Cross-validation folds\")):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "            cv_scores.append(score)\n",
    "\n",
    "            # Generazione del classification report\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            reports.append(report)\n",
    "\n",
    "            # Creazione della Confusion Matrix\n",
    "            cm_filename = os.path.join(log_path, f\"confusion_matrix_fold_{fold_idx}.png\")\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title(f'Confusion Matrix - {model_name} Fold {fold_idx}')\n",
    "            plt.savefig(cm_filename)\n",
    "            plt.close()\n",
    "\n",
    "            # Log delle metriche su MLflow\n",
    "            mlflow.log_metric(f\"accuracy_fold_{fold_idx}\", score)\n",
    "            mlflow.log_artifact(cm_filename)  # Log della Confusion Matrix su MLflow\n",
    "\n",
    "        # Log finale su MLflow\n",
    "        mlflow.log_metric(\"Mean_CV_Accuracy\", np.mean(cv_scores))\n",
    "        mlflow.log_metric(\"Std_CV_Accuracy\", np.std(cv_scores))\n",
    "\n",
    "        # Salvataggio del modello con input_example\n",
    "        input_example = pd.DataFrame(X.iloc[:1])  # Usa una riga di X come esempio di input\n",
    "        mlflow.sklearn.log_model(model, model_path, input_example=input_example)\n",
    "\n",
    "        # Salvataggio classification report come JSON\n",
    "        report_path = os.path.join(artifact_path, f\"{model_name}_classification_report.json\")\n",
    "        with open(report_path, \"w\") as f:\n",
    "            json.dump(reports, f, indent=4)\n",
    "\n",
    "        # Log del classification report come artifact su MLflow\n",
    "        mlflow.log_artifact(report_path)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"[{model_name}] Training completato in {elapsed_time:.2f} secondi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_ann(input_dim, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_ann_mlflow(X, y, subjects, folds, experiment_name):\n",
    "    print(\"\\nInizio training modello: ANN\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Imposta l'esperimento in MLflow\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run(run_name=\"ANN\"):\n",
    "        # Creazione delle directory per organizzare i file\n",
    "        experiment_path = os.path.join(\"mlruns\", experiment_name)\n",
    "        model_path = os.path.join(experiment_path, \"models\", \"ANN.h5\")\n",
    "        log_path = os.path.join(experiment_path, \"logs\", \"ANN\")\n",
    "        artifact_path = os.path.join(experiment_path, \"artifacts\", \"ANN\")\n",
    "\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        os.makedirs(log_path, exist_ok=True)\n",
    "        os.makedirs(artifact_path, exist_ok=True)\n",
    "\n",
    "        # Log dei parametri dell'ANN\n",
    "        mlflow.log_params({\n",
    "            \"Layers\": \"[128, 64, num_classes]\",\n",
    "            \"Activation\": \"relu\",\n",
    "            \"Optimizer\": \"adam\",\n",
    "            \"Learning Rate\": 0.01,\n",
    "            \"Loss\": \"sparse_categorical_crossentropy\",\n",
    "            \"Epochs\": 50,\n",
    "            \"Batch Size\": 256,\n",
    "            \"Early Stopping\": False\n",
    "        })\n",
    "\n",
    "        cv_scores = []\n",
    "        reports = []\n",
    "        training_logs = {}\n",
    "\n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(tqdm(folds, desc=\"Cross-validation folds\")):\n",
    "            model = create_ann(X.shape[1], len(np.unique(y)))\n",
    "\n",
    "            # Imposta l'optimizer con learning rate 0.01\n",
    "            model.compile(\n",
    "                optimizer=Adam(learning_rate=0.01),  # Learning rate personalizzato\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=[\"accuracy\"]\n",
    "            )\n",
    "\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            # Training senza Early Stopping\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_test, y_test),\n",
    "                epochs=50, batch_size=256,\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            # Salvataggio log di training\n",
    "            training_logs[f\"fold_{fold_idx}\"] = {\n",
    "                \"loss\": history.history[\"loss\"],\n",
    "                \"accuracy\": history.history[\"accuracy\"],\n",
    "                \"val_loss\": history.history[\"val_loss\"],\n",
    "                \"val_accuracy\": history.history[\"val_accuracy\"]\n",
    "            }\n",
    "\n",
    "            # Valutazione\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "            score = accuracy_score(y_test, y_pred_classes)\n",
    "            cv_scores.append(score)\n",
    "\n",
    "            # Generiamo il classification report\n",
    "            report = classification_report(y_test, y_pred_classes, output_dict=True)\n",
    "            reports.append(report)\n",
    "\n",
    "            # Creiamo e salviamo la Confusion Matrix\n",
    "            cm_filename = os.path.join(log_path, f\"confusion_matrix_fold_{fold_idx}.png\")\n",
    "            cm = confusion_matrix(y_test, y_pred_classes)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.title(f'Confusion Matrix - ANN Fold {fold_idx}')\n",
    "            plt.savefig(cm_filename)\n",
    "            plt.close()\n",
    "\n",
    "            # Log delle metriche su MLflow\n",
    "            mlflow.log_metric(f\"accuracy_fold_{fold_idx}\", score)\n",
    "            mlflow.log_artifact(cm_filename)  # Log della Confusion Matrix su MLflow\n",
    "\n",
    "        # Log finali\n",
    "        mlflow.log_metric(\"Mean_CV_Accuracy\", np.mean(cv_scores))\n",
    "        mlflow.log_metric(\"Std_CV_Accuracy\", np.std(cv_scores))\n",
    "\n",
    "        # Salvataggio modello ANN su MLflow con input_example\n",
    "        input_example = tf.convert_to_tensor(X.iloc[:1].values.astype(np.float32))\n",
    "        model.save(model_path)\n",
    "        mlflow.tensorflow.log_model(model, model_path, input_example=input_example)\n",
    "\n",
    "        # Salvataggio classification report come JSON\n",
    "        report_path = os.path.join(artifact_path, \"ANN_classification_report.json\")\n",
    "        with open(report_path, \"w\") as f:\n",
    "            json.dump(reports, f, indent=4)\n",
    "        mlflow.log_artifact(report_path)\n",
    "\n",
    "        # Salvataggio dei log di training\n",
    "        training_log_path = os.path.join(log_path, \"training_logs.json\")\n",
    "        with open(training_log_path, \"w\") as f:\n",
    "            json.dump(training_logs, f, indent=4)\n",
    "        mlflow.log_artifact(training_log_path)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"[ANN] Training completato in {elapsed_time:.2f} secondi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio training e logging con MLflow per l'esperimento 'Pipeline2.2'...\n",
      "\n",
      "Inizio training modello: Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation folds: 100%|██████████| 5/5 [00:21<00:00,  4.39s/it]\n",
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Random Forest at: http://127.0.0.1:5000/#/experiments/849866340618810789/runs/3a5f8ff1a8ac4ffa99f1f5789c41f801\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/849866340618810789\n",
      "[Random Forest] Training completato in 24.41 secondi.\n",
      "\n",
      "Inizio training modello: XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation folds: 100%|██████████| 5/5 [00:22<00:00,  4.45s/it]\n",
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGBoost at: http://127.0.0.1:5000/#/experiments/849866340618810789/runs/2c0a81111b1e49fe8b432662bdc0ecd9\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/849866340618810789\n",
      "[XGBoost] Training completato in 23.80 secondi.\n",
      "\n",
      "Inizio training modello: Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation folds:   0%|          | 0/5 [00:00<?, ?it/s]/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Cross-validation folds:  20%|██        | 1/5 [00:08<00:33,  8.28s/it]/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Cross-validation folds:  40%|████      | 2/5 [00:15<00:23,  7.74s/it]/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Cross-validation folds:  60%|██████    | 3/5 [00:23<00:15,  7.59s/it]/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Cross-validation folds:  80%|████████  | 4/5 [00:30<00:07,  7.44s/it]/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Cross-validation folds: 100%|██████████| 5/5 [00:37<00:00,  7.50s/it]\n",
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Logistic Regression at: http://127.0.0.1:5000/#/experiments/849866340618810789/runs/75f726a132a8477ab99ee82d3e2c7bb3\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/849866340618810789\n",
      "[Logistic Regression] Training completato in 38.82 secondi.\n",
      "\n",
      "Inizio training modello: ANN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation folds:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2259 - loss: 1827.3860 - val_accuracy: 0.1656 - val_loss: 1443.4851\n",
      "Epoch 2/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2194 - loss: 1041.2067 - val_accuracy: 0.2230 - val_loss: 677.3011\n",
      "Epoch 3/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2167 - loss: 1281.6515 - val_accuracy: 0.2045 - val_loss: 2389.6116\n",
      "Epoch 4/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2207 - loss: 1287.4535 - val_accuracy: 0.2682 - val_loss: 665.7310\n",
      "Epoch 5/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2192 - loss: 1106.2457 - val_accuracy: 0.1788 - val_loss: 3073.3044\n",
      "Epoch 6/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2153 - loss: 2091.9541 - val_accuracy: 0.1925 - val_loss: 3087.7815\n",
      "Epoch 7/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2205 - loss: 1916.8555 - val_accuracy: 0.3420 - val_loss: 929.5123\n",
      "Epoch 8/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2173 - loss: 2091.9773 - val_accuracy: 0.2515 - val_loss: 1814.0715\n",
      "Epoch 9/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2127 - loss: 2625.0842 - val_accuracy: 0.2492 - val_loss: 1718.8749\n",
      "Epoch 10/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2174 - loss: 2650.5430 - val_accuracy: 0.2518 - val_loss: 2754.6047\n",
      "Epoch 11/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2176 - loss: 2586.6519 - val_accuracy: 0.2328 - val_loss: 1574.8475\n",
      "Epoch 12/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2147 - loss: 2816.3577 - val_accuracy: 0.2049 - val_loss: 2479.1868\n",
      "Epoch 13/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2236 - loss: 2345.5012 - val_accuracy: 0.1690 - val_loss: 17076.3828\n",
      "Epoch 14/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1989 - loss: 8920.2070 - val_accuracy: 0.2209 - val_loss: 6838.2124\n",
      "Epoch 15/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2203 - loss: 3949.6069 - val_accuracy: 0.2158 - val_loss: 4714.1011\n",
      "Epoch 16/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2237 - loss: 3024.8176 - val_accuracy: 0.2020 - val_loss: 5283.4502\n",
      "Epoch 17/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2161 - loss: 3752.4600 - val_accuracy: 0.2236 - val_loss: 2506.8877\n",
      "Epoch 18/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2195 - loss: 2653.9163 - val_accuracy: 0.2892 - val_loss: 3741.9189\n",
      "Epoch 19/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2231 - loss: 2758.4822 - val_accuracy: 0.1788 - val_loss: 4861.7710\n",
      "Epoch 20/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2194 - loss: 3528.1875 - val_accuracy: 0.1910 - val_loss: 4000.8704\n",
      "Epoch 21/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2185 - loss: 3446.4866 - val_accuracy: 0.2686 - val_loss: 2600.5090\n",
      "Epoch 22/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2117 - loss: 4007.3909 - val_accuracy: 0.2774 - val_loss: 2658.7410\n",
      "Epoch 23/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2243 - loss: 3236.5425 - val_accuracy: 0.1640 - val_loss: 3355.0364\n",
      "Epoch 24/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2262 - loss: 2778.1040 - val_accuracy: 0.2980 - val_loss: 5345.6348\n",
      "Epoch 25/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2211 - loss: 4061.9688 - val_accuracy: 0.1859 - val_loss: 4970.8135\n",
      "Epoch 26/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2146 - loss: 3208.0417 - val_accuracy: 0.2444 - val_loss: 1952.5305\n",
      "Epoch 27/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2288 - loss: 3521.3489 - val_accuracy: 0.1622 - val_loss: 5451.6260\n",
      "Epoch 28/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2251 - loss: 4893.7075 - val_accuracy: 0.2868 - val_loss: 5786.4023\n",
      "Epoch 29/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2203 - loss: 5914.7627 - val_accuracy: 0.1714 - val_loss: 9959.1670\n",
      "Epoch 30/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2172 - loss: 5875.2119 - val_accuracy: 0.2025 - val_loss: 6630.7090\n",
      "Epoch 31/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2144 - loss: 6965.2158 - val_accuracy: 0.2048 - val_loss: 5079.9111\n",
      "Epoch 32/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2217 - loss: 4422.9805 - val_accuracy: 0.2919 - val_loss: 1886.5309\n",
      "Epoch 33/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1949 - loss: 20590.9180 - val_accuracy: 0.1916 - val_loss: 12454.8164\n",
      "Epoch 34/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2083 - loss: 13657.7070 - val_accuracy: 0.2482 - val_loss: 7993.5835\n",
      "Epoch 35/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2081 - loss: 12758.8574 - val_accuracy: 0.1789 - val_loss: 17437.4609\n",
      "Epoch 36/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2096 - loss: 10779.7627 - val_accuracy: 0.1887 - val_loss: 18124.6699\n",
      "Epoch 37/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2082 - loss: 11488.4971 - val_accuracy: 0.2342 - val_loss: 7581.7354\n",
      "Epoch 38/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2179 - loss: 9742.9521 - val_accuracy: 0.2086 - val_loss: 11248.0127\n",
      "Epoch 39/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2131 - loss: 10677.0566 - val_accuracy: 0.2174 - val_loss: 11161.4922\n",
      "Epoch 40/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2204 - loss: 9597.8389 - val_accuracy: 0.3291 - val_loss: 4776.2490\n",
      "Epoch 41/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2277 - loss: 8473.1201 - val_accuracy: 0.2826 - val_loss: 3018.0713\n",
      "Epoch 42/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2166 - loss: 9847.7490 - val_accuracy: 0.2356 - val_loss: 5198.8101\n",
      "Epoch 43/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2179 - loss: 8623.8857 - val_accuracy: 0.2307 - val_loss: 5510.6450\n",
      "Epoch 44/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2124 - loss: 11580.7656 - val_accuracy: 0.1621 - val_loss: 18435.1230\n",
      "Epoch 45/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2160 - loss: 9778.3965 - val_accuracy: 0.2702 - val_loss: 6423.2915\n",
      "Epoch 46/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2128 - loss: 11476.1367 - val_accuracy: 0.1841 - val_loss: 8613.8730\n",
      "Epoch 47/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2241 - loss: 10797.1562 - val_accuracy: 0.3168 - val_loss: 7457.7715\n",
      "Epoch 48/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2183 - loss: 9906.1309 - val_accuracy: 0.2244 - val_loss: 13387.5195\n",
      "Epoch 49/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2169 - loss: 13208.0049 - val_accuracy: 0.1918 - val_loss: 17061.8672\n",
      "Epoch 50/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2257 - loss: 9884.1406 - val_accuracy: 0.2749 - val_loss: 13444.5830\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Cross-validation folds:  20%|██        | 1/5 [01:13<04:53, 73.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2219 - loss: 2101.6199 - val_accuracy: 0.2771 - val_loss: 1094.6464\n",
      "Epoch 2/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2292 - loss: 1124.5815 - val_accuracy: 0.2062 - val_loss: 2196.7004\n",
      "Epoch 3/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2095 - loss: 2570.0449 - val_accuracy: 0.2160 - val_loss: 1880.7148\n",
      "Epoch 4/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2200 - loss: 1922.7264 - val_accuracy: 0.2710 - val_loss: 1889.2382\n",
      "Epoch 5/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2223 - loss: 2017.3127 - val_accuracy: 0.1560 - val_loss: 3163.4592\n",
      "Epoch 6/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2092 - loss: 4060.5188 - val_accuracy: 0.2222 - val_loss: 2714.1616\n",
      "Epoch 7/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2261 - loss: 4125.6216 - val_accuracy: 0.2743 - val_loss: 2585.0510\n",
      "Epoch 8/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2220 - loss: 4556.3115 - val_accuracy: 0.2526 - val_loss: 2529.9407\n",
      "Epoch 9/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2290 - loss: 4946.9604 - val_accuracy: 0.2528 - val_loss: 3103.9077\n",
      "Epoch 10/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2182 - loss: 6776.0444 - val_accuracy: 0.2319 - val_loss: 6515.2720\n",
      "Epoch 11/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2197 - loss: 9564.9736 - val_accuracy: 0.1699 - val_loss: 14075.5293\n",
      "Epoch 12/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2210 - loss: 9704.2764 - val_accuracy: 0.2452 - val_loss: 10415.3906\n",
      "Epoch 13/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2170 - loss: 10179.0322 - val_accuracy: 0.2250 - val_loss: 6302.9775\n",
      "Epoch 14/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2206 - loss: 8221.2900 - val_accuracy: 0.2862 - val_loss: 5238.0811\n",
      "Epoch 15/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2213 - loss: 9089.5342 - val_accuracy: 0.1495 - val_loss: 7280.5938\n",
      "Epoch 16/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2240 - loss: 9056.6338 - val_accuracy: 0.2452 - val_loss: 14780.4736\n",
      "Epoch 17/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2249 - loss: 15265.1738 - val_accuracy: 0.1801 - val_loss: 16092.1221\n",
      "Epoch 18/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2229 - loss: 13847.8252 - val_accuracy: 0.2286 - val_loss: 8315.4180\n",
      "Epoch 19/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2223 - loss: 14051.9531 - val_accuracy: 0.2155 - val_loss: 21776.6484\n",
      "Epoch 20/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2219 - loss: 17660.6973 - val_accuracy: 0.2350 - val_loss: 21932.6211\n",
      "Epoch 21/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2257 - loss: 19590.7793 - val_accuracy: 0.2157 - val_loss: 15405.3867\n",
      "Epoch 22/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2293 - loss: 23038.8496 - val_accuracy: 0.2926 - val_loss: 22083.6777\n",
      "Epoch 23/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2257 - loss: 29331.5137 - val_accuracy: 0.2233 - val_loss: 13504.1104\n",
      "Epoch 24/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2225 - loss: 26342.3359 - val_accuracy: 0.2602 - val_loss: 24355.4492\n",
      "Epoch 25/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2282 - loss: 22636.0039 - val_accuracy: 0.2425 - val_loss: 27845.9648\n",
      "Epoch 26/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2355 - loss: 24068.2969 - val_accuracy: 0.2486 - val_loss: 38414.7031\n",
      "Epoch 27/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2327 - loss: 31455.9004 - val_accuracy: 0.2039 - val_loss: 51869.4023\n",
      "Epoch 28/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2291 - loss: 33419.0430 - val_accuracy: 0.1970 - val_loss: 19528.2012\n",
      "Epoch 29/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2256 - loss: 42994.6055 - val_accuracy: 0.2154 - val_loss: 33198.6914\n",
      "Epoch 30/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2249 - loss: 50755.8789 - val_accuracy: 0.2173 - val_loss: 31902.1973\n",
      "Epoch 31/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2262 - loss: 47497.6641 - val_accuracy: 0.2286 - val_loss: 34196.4102\n",
      "Epoch 32/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2238 - loss: 41399.8555 - val_accuracy: 0.2037 - val_loss: 45356.7383\n",
      "Epoch 33/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2307 - loss: 49829.9062 - val_accuracy: 0.1827 - val_loss: 41893.4609\n",
      "Epoch 34/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2284 - loss: 48006.1172 - val_accuracy: 0.2745 - val_loss: 56669.0508\n",
      "Epoch 35/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2303 - loss: 49461.1797 - val_accuracy: 0.2437 - val_loss: 61509.4375\n",
      "Epoch 36/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2325 - loss: 54727.7812 - val_accuracy: 0.2102 - val_loss: 69088.1953\n",
      "Epoch 37/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2318 - loss: 49818.1680 - val_accuracy: 0.2098 - val_loss: 90553.9922\n",
      "Epoch 38/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2344 - loss: 54184.3164 - val_accuracy: 0.2425 - val_loss: 57296.2656\n",
      "Epoch 39/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2261 - loss: 64774.6133 - val_accuracy: 0.3502 - val_loss: 74844.0234\n",
      "Epoch 40/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2339 - loss: 71335.7891 - val_accuracy: 0.2307 - val_loss: 76304.3438\n",
      "Epoch 41/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2330 - loss: 67366.4297 - val_accuracy: 0.1973 - val_loss: 47624.8711\n",
      "Epoch 42/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2252 - loss: 69617.3203 - val_accuracy: 0.1992 - val_loss: 33249.8750\n",
      "Epoch 43/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2353 - loss: 71910.8672 - val_accuracy: 0.1668 - val_loss: 92637.8984\n",
      "Epoch 44/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2280 - loss: 69862.1016 - val_accuracy: 0.2352 - val_loss: 86386.7109\n",
      "Epoch 45/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2313 - loss: 91761.4297 - val_accuracy: 0.2949 - val_loss: 97851.9141\n",
      "Epoch 46/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2376 - loss: 79942.8984 - val_accuracy: 0.2984 - val_loss: 39267.3359\n",
      "Epoch 47/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2259 - loss: 90334.8516 - val_accuracy: 0.2199 - val_loss: 104745.3516\n",
      "Epoch 48/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2242 - loss: 90075.2812 - val_accuracy: 0.2468 - val_loss: 74381.0859\n",
      "Epoch 49/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2347 - loss: 88856.3516 - val_accuracy: 0.3170 - val_loss: 45068.4023\n",
      "Epoch 50/50\n",
      "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2306 - loss: 88769.5156 - val_accuracy: 0.2288 - val_loss: 66792.5859\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation folds:  40%|████      | 2/5 [02:27<03:41, 73.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2330 - loss: 1810.4333 - val_accuracy: 0.1610 - val_loss: 1497.9688\n",
      "Epoch 2/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2230 - loss: 1091.0071 - val_accuracy: 0.3032 - val_loss: 799.7609\n",
      "Epoch 3/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2376 - loss: 1001.0250 - val_accuracy: 0.2095 - val_loss: 944.8156\n",
      "Epoch 4/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2197 - loss: 1363.4332 - val_accuracy: 0.2139 - val_loss: 1251.5623\n",
      "Epoch 5/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2205 - loss: 1174.9569 - val_accuracy: 0.2071 - val_loss: 1801.1781\n",
      "Epoch 6/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2244 - loss: 1197.1238 - val_accuracy: 0.2932 - val_loss: 1009.6970\n",
      "Epoch 7/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2174 - loss: 1914.5651 - val_accuracy: 0.2411 - val_loss: 1454.1926\n",
      "Epoch 8/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2186 - loss: 2397.2073 - val_accuracy: 0.2257 - val_loss: 2795.1270\n",
      "Epoch 9/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2167 - loss: 2028.8646 - val_accuracy: 0.1757 - val_loss: 2537.8232\n",
      "Epoch 10/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2181 - loss: 1987.5170 - val_accuracy: 0.2824 - val_loss: 1971.1979\n",
      "Epoch 11/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2130 - loss: 2147.2522 - val_accuracy: 0.2193 - val_loss: 2003.2858\n",
      "Epoch 12/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2193 - loss: 1837.7319 - val_accuracy: 0.2308 - val_loss: 2436.8618\n",
      "Epoch 13/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2192 - loss: 2022.3748 - val_accuracy: 0.1612 - val_loss: 4011.9387\n",
      "Epoch 14/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2172 - loss: 1993.5590 - val_accuracy: 0.2058 - val_loss: 2202.7734\n",
      "Epoch 15/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2067 - loss: 2585.3491 - val_accuracy: 0.2742 - val_loss: 808.1469\n",
      "Epoch 16/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2186 - loss: 2139.5750 - val_accuracy: 0.2243 - val_loss: 2387.6082\n",
      "Epoch 17/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2258 - loss: 2073.1875 - val_accuracy: 0.2941 - val_loss: 2282.7122\n",
      "Epoch 18/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2138 - loss: 8220.6016 - val_accuracy: 0.1657 - val_loss: 15908.1025\n",
      "Epoch 19/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2180 - loss: 10564.0205 - val_accuracy: 0.2362 - val_loss: 16204.9912\n",
      "Epoch 20/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2119 - loss: 10516.2051 - val_accuracy: 0.1932 - val_loss: 11004.6846\n",
      "Epoch 21/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2203 - loss: 7828.7661 - val_accuracy: 0.1612 - val_loss: 16316.2480\n",
      "Epoch 22/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2183 - loss: 8049.6763 - val_accuracy: 0.2851 - val_loss: 3785.9697\n",
      "Epoch 23/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2181 - loss: 8737.8438 - val_accuracy: 0.2678 - val_loss: 3313.9070\n",
      "Epoch 24/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2277 - loss: 9044.7393 - val_accuracy: 0.1718 - val_loss: 11914.8066\n",
      "Epoch 25/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2283 - loss: 6892.2310 - val_accuracy: 0.2473 - val_loss: 5943.6304\n",
      "Epoch 26/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2288 - loss: 5941.1333 - val_accuracy: 0.2135 - val_loss: 8878.7188\n",
      "Epoch 27/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2211 - loss: 7870.6631 - val_accuracy: 0.2714 - val_loss: 10232.9268\n",
      "Epoch 28/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2187 - loss: 7953.0791 - val_accuracy: 0.2238 - val_loss: 9905.2744\n",
      "Epoch 29/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2257 - loss: 6953.7803 - val_accuracy: 0.2664 - val_loss: 5182.1738\n",
      "Epoch 30/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2282 - loss: 7055.1680 - val_accuracy: 0.1626 - val_loss: 6207.1206\n",
      "Epoch 31/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2158 - loss: 7550.8086 - val_accuracy: 0.2544 - val_loss: 7012.1772\n",
      "Epoch 32/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2268 - loss: 7630.2588 - val_accuracy: 0.2304 - val_loss: 11250.0107\n",
      "Epoch 33/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2247 - loss: 7075.7476 - val_accuracy: 0.3229 - val_loss: 9504.3652\n",
      "Epoch 34/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2293 - loss: 7564.2080 - val_accuracy: 0.2855 - val_loss: 4776.7363\n",
      "Epoch 35/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2203 - loss: 7134.9067 - val_accuracy: 0.2706 - val_loss: 8645.1641\n",
      "Epoch 36/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2299 - loss: 7863.3555 - val_accuracy: 0.2192 - val_loss: 9827.9971\n",
      "Epoch 37/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2220 - loss: 10046.1719 - val_accuracy: 0.2983 - val_loss: 8112.3569\n",
      "Epoch 38/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2197 - loss: 9841.0840 - val_accuracy: 0.2113 - val_loss: 23104.2285\n",
      "Epoch 39/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2202 - loss: 14175.3672 - val_accuracy: 0.2543 - val_loss: 5883.2617\n",
      "Epoch 40/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2270 - loss: 13705.0654 - val_accuracy: 0.1849 - val_loss: 17849.2383\n",
      "Epoch 41/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2166 - loss: 13696.7354 - val_accuracy: 0.1667 - val_loss: 16976.7246\n",
      "Epoch 42/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2130 - loss: 16933.2734 - val_accuracy: 0.2188 - val_loss: 16824.7461\n",
      "Epoch 43/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2205 - loss: 18159.5820 - val_accuracy: 0.1743 - val_loss: 23774.0352\n",
      "Epoch 44/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2241 - loss: 16829.8418 - val_accuracy: 0.1719 - val_loss: 39162.6680\n",
      "Epoch 45/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2232 - loss: 22523.3770 - val_accuracy: 0.2411 - val_loss: 22601.5977\n",
      "Epoch 46/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2281 - loss: 19164.9551 - val_accuracy: 0.2182 - val_loss: 30822.1680\n",
      "Epoch 47/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2262 - loss: 18903.1309 - val_accuracy: 0.2243 - val_loss: 22503.9688\n",
      "Epoch 48/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2187 - loss: 24085.2910 - val_accuracy: 0.2667 - val_loss: 24391.3438\n",
      "Epoch 49/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2315 - loss: 21702.6113 - val_accuracy: 0.2458 - val_loss: 24285.9004\n",
      "Epoch 50/50\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2233 - loss: 21664.2520 - val_accuracy: 0.2802 - val_loss: 26167.3809\n",
      "\u001b[1m459/459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Cross-validation folds:  60%|██████    | 3/5 [03:42<02:28, 74.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2240 - loss: 2494.5156 - val_accuracy: 0.2067 - val_loss: 1096.2981\n",
      "Epoch 2/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2250 - loss: 1006.5135 - val_accuracy: 0.1868 - val_loss: 981.1723\n",
      "Epoch 3/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2209 - loss: 990.9155 - val_accuracy: 0.2746 - val_loss: 505.2694\n",
      "Epoch 4/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2259 - loss: 914.1170 - val_accuracy: 0.1950 - val_loss: 878.8011\n",
      "Epoch 5/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2197 - loss: 1077.6969 - val_accuracy: 0.2562 - val_loss: 574.5980\n",
      "Epoch 6/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2207 - loss: 1110.0035 - val_accuracy: 0.2139 - val_loss: 998.4957\n",
      "Epoch 7/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2227 - loss: 1197.2201 - val_accuracy: 0.2476 - val_loss: 699.3078\n",
      "Epoch 8/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2262 - loss: 1213.5917 - val_accuracy: 0.2553 - val_loss: 784.0610\n",
      "Epoch 9/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2382 - loss: 1034.2432 - val_accuracy: 0.2037 - val_loss: 813.0294\n",
      "Epoch 10/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2243 - loss: 1080.6116 - val_accuracy: 0.2194 - val_loss: 977.4504\n",
      "Epoch 11/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2268 - loss: 1457.9598 - val_accuracy: 0.2938 - val_loss: 289.8393\n",
      "Epoch 12/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2319 - loss: 1158.8905 - val_accuracy: 0.1957 - val_loss: 701.1046\n",
      "Epoch 13/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2257 - loss: 1377.3082 - val_accuracy: 0.2033 - val_loss: 1643.8737\n",
      "Epoch 14/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2206 - loss: 1864.7843 - val_accuracy: 0.2385 - val_loss: 2675.9585\n",
      "Epoch 15/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2103 - loss: 3941.5930 - val_accuracy: 0.1687 - val_loss: 3631.0488\n",
      "Epoch 16/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2202 - loss: 3200.5403 - val_accuracy: 0.2116 - val_loss: 3979.8040\n",
      "Epoch 17/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2307 - loss: 2323.4753 - val_accuracy: 0.1868 - val_loss: 4570.3394\n",
      "Epoch 18/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2184 - loss: 2785.7490 - val_accuracy: 0.2334 - val_loss: 2522.2314\n",
      "Epoch 19/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2241 - loss: 2338.3647 - val_accuracy: 0.2250 - val_loss: 1184.4932\n",
      "Epoch 20/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2312 - loss: 2071.8960 - val_accuracy: 0.2142 - val_loss: 927.9836\n",
      "Epoch 21/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2258 - loss: 2061.3748 - val_accuracy: 0.2022 - val_loss: 3565.3000\n",
      "Epoch 22/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2241 - loss: 2478.1726 - val_accuracy: 0.2195 - val_loss: 9477.2949\n",
      "Epoch 23/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2037 - loss: 9784.1309 - val_accuracy: 0.2149 - val_loss: 3264.5195\n",
      "Epoch 24/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2238 - loss: 4934.6177 - val_accuracy: 0.2300 - val_loss: 4303.6133\n",
      "Epoch 25/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2216 - loss: 4872.9561 - val_accuracy: 0.1956 - val_loss: 4650.5728\n",
      "Epoch 26/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2164 - loss: 4785.8970 - val_accuracy: 0.2510 - val_loss: 1742.3097\n",
      "Epoch 27/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2235 - loss: 4292.8306 - val_accuracy: 0.1696 - val_loss: 8067.0693\n",
      "Epoch 28/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2059 - loss: 8594.6924 - val_accuracy: 0.2252 - val_loss: 2711.3677\n",
      "Epoch 29/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2094 - loss: 5443.6255 - val_accuracy: 0.2406 - val_loss: 2127.0156\n",
      "Epoch 30/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2288 - loss: 3887.3594 - val_accuracy: 0.2544 - val_loss: 1701.1105\n",
      "Epoch 31/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2300 - loss: 5259.0996 - val_accuracy: 0.2937 - val_loss: 3700.5869\n",
      "Epoch 32/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2261 - loss: 4578.5693 - val_accuracy: 0.2461 - val_loss: 2082.5911\n",
      "Epoch 33/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2213 - loss: 4153.4810 - val_accuracy: 0.2510 - val_loss: 3407.9619\n",
      "Epoch 34/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2142 - loss: 5300.9717 - val_accuracy: 0.2001 - val_loss: 5816.1455\n",
      "Epoch 35/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2229 - loss: 5057.1357 - val_accuracy: 0.2156 - val_loss: 5252.9019\n",
      "Epoch 36/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2215 - loss: 4818.0762 - val_accuracy: 0.2020 - val_loss: 5404.0718\n",
      "Epoch 37/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2188 - loss: 4631.6235 - val_accuracy: 0.1965 - val_loss: 6963.9082\n",
      "Epoch 38/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2207 - loss: 5338.4849 - val_accuracy: 0.1697 - val_loss: 3993.4421\n",
      "Epoch 39/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2183 - loss: 5464.1309 - val_accuracy: 0.2067 - val_loss: 4043.1082\n",
      "Epoch 40/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2222 - loss: 4751.0015 - val_accuracy: 0.2497 - val_loss: 3562.9844\n",
      "Epoch 41/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2220 - loss: 4222.8447 - val_accuracy: 0.2570 - val_loss: 2932.7642\n",
      "Epoch 42/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2196 - loss: 4006.5642 - val_accuracy: 0.2071 - val_loss: 2762.2710\n",
      "Epoch 43/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2240 - loss: 4237.8882 - val_accuracy: 0.1703 - val_loss: 4536.7192\n",
      "Epoch 44/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2234 - loss: 4392.9375 - val_accuracy: 0.2748 - val_loss: 3861.7903\n",
      "Epoch 45/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2300 - loss: 4658.0269 - val_accuracy: 0.1941 - val_loss: 5282.1807\n",
      "Epoch 46/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2156 - loss: 4441.6572 - val_accuracy: 0.1756 - val_loss: 3752.8567\n",
      "Epoch 47/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2248 - loss: 4846.1357 - val_accuracy: 0.2073 - val_loss: 5172.7583\n",
      "Epoch 48/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2129 - loss: 5761.6445 - val_accuracy: 0.2512 - val_loss: 6271.8228\n",
      "Epoch 49/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2295 - loss: 5283.8086 - val_accuracy: 0.2690 - val_loss: 3535.5151\n",
      "Epoch 50/50\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2367 - loss: 3943.6768 - val_accuracy: 0.2010 - val_loss: 3626.7458\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Cross-validation folds:  80%|████████  | 4/5 [04:56<01:14, 74.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2500 - loss: 1928.5834 - val_accuracy: 0.2128 - val_loss: 1518.1959\n",
      "Epoch 2/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2411 - loss: 988.0105 - val_accuracy: 0.1935 - val_loss: 1094.0426\n",
      "Epoch 3/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2380 - loss: 1057.3955 - val_accuracy: 0.1900 - val_loss: 694.8416\n",
      "Epoch 4/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2311 - loss: 1000.6034 - val_accuracy: 0.2489 - val_loss: 779.7884\n",
      "Epoch 5/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2409 - loss: 970.9927 - val_accuracy: 0.1869 - val_loss: 1520.9258\n",
      "Epoch 6/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2351 - loss: 1181.1426 - val_accuracy: 0.2331 - val_loss: 1230.4032\n",
      "Epoch 7/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2429 - loss: 1033.5676 - val_accuracy: 0.2532 - val_loss: 820.1736\n",
      "Epoch 8/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2321 - loss: 1102.7236 - val_accuracy: 0.2490 - val_loss: 1453.7133\n",
      "Epoch 9/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2385 - loss: 1208.5642 - val_accuracy: 0.2453 - val_loss: 729.2866\n",
      "Epoch 10/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2475 - loss: 900.7810 - val_accuracy: 0.1932 - val_loss: 745.0527\n",
      "Epoch 11/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2393 - loss: 879.6334 - val_accuracy: 0.2193 - val_loss: 1004.1219\n",
      "Epoch 12/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2359 - loss: 1018.7528 - val_accuracy: 0.2255 - val_loss: 1021.9421\n",
      "Epoch 13/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2406 - loss: 955.9999 - val_accuracy: 0.1838 - val_loss: 901.0442\n",
      "Epoch 14/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2305 - loss: 1036.8770 - val_accuracy: 0.1667 - val_loss: 1151.8794\n",
      "Epoch 15/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2365 - loss: 1090.0602 - val_accuracy: 0.1927 - val_loss: 1303.5101\n",
      "Epoch 16/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2426 - loss: 933.0979 - val_accuracy: 0.2628 - val_loss: 972.1390\n",
      "Epoch 17/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2404 - loss: 986.7117 - val_accuracy: 0.1659 - val_loss: 1267.4685\n",
      "Epoch 18/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2304 - loss: 1382.1486 - val_accuracy: 0.1800 - val_loss: 1777.3464\n",
      "Epoch 19/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2481 - loss: 1039.0577 - val_accuracy: 0.1802 - val_loss: 1263.9937\n",
      "Epoch 20/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2345 - loss: 1085.4230 - val_accuracy: 0.2335 - val_loss: 1050.8560\n",
      "Epoch 21/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2395 - loss: 1001.3008 - val_accuracy: 0.1858 - val_loss: 1418.4646\n",
      "Epoch 22/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2435 - loss: 1051.8595 - val_accuracy: 0.2144 - val_loss: 539.1436\n",
      "Epoch 23/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2414 - loss: 889.5139 - val_accuracy: 0.1865 - val_loss: 1328.9238\n",
      "Epoch 24/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2430 - loss: 944.4584 - val_accuracy: 0.2290 - val_loss: 736.7392\n",
      "Epoch 25/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2343 - loss: 989.4702 - val_accuracy: 0.2151 - val_loss: 1575.2030\n",
      "Epoch 26/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2417 - loss: 885.9288 - val_accuracy: 0.1682 - val_loss: 1299.8901\n",
      "Epoch 27/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2417 - loss: 1093.2533 - val_accuracy: 0.2284 - val_loss: 771.8402\n",
      "Epoch 28/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2462 - loss: 896.4153 - val_accuracy: 0.2239 - val_loss: 1139.8470\n",
      "Epoch 29/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2397 - loss: 972.3732 - val_accuracy: 0.2326 - val_loss: 442.1316\n",
      "Epoch 30/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2396 - loss: 975.8001 - val_accuracy: 0.2374 - val_loss: 728.1862\n",
      "Epoch 31/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2456 - loss: 949.9669 - val_accuracy: 0.1914 - val_loss: 793.7474\n",
      "Epoch 32/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2376 - loss: 998.6792 - val_accuracy: 0.1903 - val_loss: 1023.8635\n",
      "Epoch 33/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2501 - loss: 870.2635 - val_accuracy: 0.1781 - val_loss: 1064.8154\n",
      "Epoch 34/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2401 - loss: 1025.3865 - val_accuracy: 0.2001 - val_loss: 725.9077\n",
      "Epoch 35/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2429 - loss: 919.2366 - val_accuracy: 0.2101 - val_loss: 918.0021\n",
      "Epoch 36/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2442 - loss: 936.8218 - val_accuracy: 0.2198 - val_loss: 669.9965\n",
      "Epoch 37/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2465 - loss: 975.1680 - val_accuracy: 0.2571 - val_loss: 553.1714\n",
      "Epoch 38/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2442 - loss: 980.7044 - val_accuracy: 0.1712 - val_loss: 1643.1410\n",
      "Epoch 39/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2357 - loss: 1197.9200 - val_accuracy: 0.1799 - val_loss: 1204.7065\n",
      "Epoch 40/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2315 - loss: 1054.8112 - val_accuracy: 0.2403 - val_loss: 727.0476\n",
      "Epoch 41/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2477 - loss: 922.1370 - val_accuracy: 0.1844 - val_loss: 1144.6447\n",
      "Epoch 42/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2452 - loss: 1026.6086 - val_accuracy: 0.1813 - val_loss: 1673.1545\n",
      "Epoch 43/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2442 - loss: 1082.5939 - val_accuracy: 0.1732 - val_loss: 935.1602\n",
      "Epoch 44/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2495 - loss: 866.5344 - val_accuracy: 0.2273 - val_loss: 1437.4618\n",
      "Epoch 45/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2414 - loss: 1003.1655 - val_accuracy: 0.1637 - val_loss: 1898.5923\n",
      "Epoch 46/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2400 - loss: 983.0687 - val_accuracy: 0.2473 - val_loss: 1279.3068\n",
      "Epoch 47/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2417 - loss: 1085.5045 - val_accuracy: 0.1993 - val_loss: 1045.0603\n",
      "Epoch 48/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2422 - loss: 1116.8986 - val_accuracy: 0.1968 - val_loss: 1655.4248\n",
      "Epoch 49/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2423 - loss: 1116.1902 - val_accuracy: 0.1814 - val_loss: 1831.1627\n",
      "Epoch 50/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2351 - loss: 1030.5464 - val_accuracy: 0.1814 - val_loss: 1084.2318\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/giorgio/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Cross-validation folds: 100%|██████████| 5/5 [06:08<00:00, 73.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run ANN at: http://127.0.0.1:5000/#/experiments/849866340618810789/runs/5f7d8d61ff4a4e43b9664296db3fa8d2\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/849866340618810789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=mlruns/Pipeline2.2/models/ANN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     train_and_evaluate_mlflow(model_name, model, X, y, subjects, folds, experiment_name)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Allenamento per il modello ANN\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrain_and_evaluate_ann_mlflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Training completato per tutti i modelli! Controlla MLflow UI per i risultati dell\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mesperimento \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 107\u001b[0m, in \u001b[0;36mtrain_and_evaluate_ann_mlflow\u001b[0;34m(X, y, subjects, folds, experiment_name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Salvataggio modello ANN su MLflow con input_example\u001b[39;00m\n\u001b[1;32m    106\u001b[0m input_example \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(X\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m--> 107\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mtensorflow\u001b[38;5;241m.\u001b[39mlog_model(model, model_path, input_example\u001b[38;5;241m=\u001b[39minput_example)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Salvataggio classification report come JSON\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/SmartphonePositioning/tf-venv/lib/python3.11/site-packages/keras/src/saving/saving_api.py:114\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39msave_model_to_hdf5(\n\u001b[1;32m    112\u001b[0m         model, filepath, overwrite, include_optimizer\n\u001b[1;32m    113\u001b[0m     )\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filepath extension for saving. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease add either a `.keras` extension for the native Keras \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat (recommended) or a `.h5` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `model.export(filepath)` if you want to export a SavedModel \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor use with TFLite/TFServing/etc. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=mlruns/Pipeline2.2/models/ANN."
     ]
    }
   ],
   "source": [
    "# Definisci il nome dell'esperimento\n",
    "experiment_name = \"Pipeline2.2\"\n",
    "\n",
    "print(f\"Inizio training e logging con MLflow per l'esperimento '{experiment_name}'...\")\n",
    "\n",
    "# Allenamento per i modelli classici (Random Forest, XGBoost, Logistic Regression)\n",
    "for model_name, model in models.items():\n",
    "    train_and_evaluate_mlflow(model_name, model, X, y, subjects, folds, experiment_name)\n",
    "\n",
    "# Allenamento per il modello ANN\n",
    "train_and_evaluate_ann_mlflow(X, y, subjects, folds, experiment_name)\n",
    "\n",
    "print(f\"✅ Training completato per tutti i modelli! Controlla MLflow UI per i risultati dell'esperimento '{experiment_name}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
